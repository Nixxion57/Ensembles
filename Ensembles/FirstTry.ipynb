{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Ensembles Assignment\n",
    "- import all necessary libraries"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "266389f66b21ece5"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-03T12:01:48.432657400Z",
     "start_time": "2024-01-03T12:01:48.415748800Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import fetch_openml\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 1. Load the MNIST dataset (given below) and split it into training, validation and test sets ."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aa204978fbec218d"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikol\\PycharmProjects\\Ensembles\\.virtualenv\\venv\\lib\\site-packages\\sklearn\\datasets\\_openml.py:75: RuntimeWarning: Invalid cache, redownloading file\n",
      "  warn(\"Invalid cache, redownloading file\", RuntimeWarning)\n",
      "C:\\Users\\nikol\\PycharmProjects\\Ensembles\\.virtualenv\\venv\\lib\\site-packages\\sklearn\\datasets\\_openml.py:110: UserWarning: A network error occurred while downloading https://api.openml.org/data/v1/download/52667. Retrying...\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "dict_keys(['data', 'target', 'frame', 'categories', 'feature_names', 'target_names', 'DESCR', 'details', 'url'])"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "# mnist_df = pd.DataFrame(mnist.data, columns=mnist.feature_names)\n",
    "mnist.keys()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T12:01:20.298563Z",
     "start_time": "2024-01-03T11:59:56.448403300Z"
    }
   },
   "id": "ce9ba67416b6cd92"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The first train_test_split is used to split the dataset into a training set (X_train, y_train) and a temporary set (X_temp, y_temp). The second train_test_split then splits the temporary set into a validation set (X_val, y_val) and a test set (X_test, y_test)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b94db27426a12a2a"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T12:04:09.131575300Z",
     "start_time": "2024-01-03T12:04:08.321879500Z"
    }
   },
   "id": "593a81785a569fdf"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# I have trained the individual classifiers on the train sets  and evaluated them on the validation set in order to check their individual performance before using the voting classifier."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e91d6dc8e40b0367"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The validation set (X_val, y_val) is used here because we are interested in assessing the classifier's performance during the development phase to avoid overfitting. Diverse models capture different aspects of the data. The validation set helps fine-tune model parameters, ensuring better adaptability to the underlying patterns in the data."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8e34186cde7414e5"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier accuracy: 0.9648571428571429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikol\\PycharmProjects\\Ensembles\\.virtualenv\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier accuracy: 0.951\n",
      "SVC accuracy: 0.975\n"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "nn_clf = MLPClassifier(hidden_layer_sizes=(100,), max_iter=20, random_state=42)\n",
    "svm_clf = SVC(probability=True, random_state=42)\n",
    "\n",
    "classifiers = [rf_clf, nn_clf, svm_clf]\n",
    "\n",
    "for clf in classifiers:\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_val_pred = clf.predict(X_val)\n",
    "    print(f\"{clf.__class__.__name__} accuracy: {accuracy_score(y_val, y_val_pred)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T12:42:40.328822600Z",
     "start_time": "2024-01-03T12:22:34.928174700Z"
    }
   },
   "id": "a081017dca55641a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The voting ensemble leverages the collective wisdom of all models improving the overall accuracy and robustness. I've opted to test it on an independent set  to ensure it's ability to generalize. I have chosen the soft vote rule based on performance. Because instead of taking the majority of the votes it takes the average of the probabilities of each class and predicts the class with the highest probability. This is more accurate than the hard vote rule."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7267317eb3ac1ceb"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikol\\PycharmProjects\\Ensembles\\.virtualenv\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "VotingClassifier(estimators=[('rf', RandomForestClassifier(random_state=42)),\n                             ('nn',\n                              MLPClassifier(max_iter=20, random_state=42)),\n                             ('svm', SVC(probability=True, random_state=42))],\n                 voting='soft')",
      "text/html": "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>VotingClassifier(estimators=[(&#x27;rf&#x27;, RandomForestClassifier(random_state=42)),\n                             (&#x27;nn&#x27;,\n                              MLPClassifier(max_iter=20, random_state=42)),\n                             (&#x27;svm&#x27;, SVC(probability=True, random_state=42))],\n                 voting=&#x27;soft&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">VotingClassifier</label><div class=\"sk-toggleable__content\"><pre>VotingClassifier(estimators=[(&#x27;rf&#x27;, RandomForestClassifier(random_state=42)),\n                             (&#x27;nn&#x27;,\n                              MLPClassifier(max_iter=20, random_state=42)),\n                             (&#x27;svm&#x27;, SVC(probability=True, random_state=42))],\n                 voting=&#x27;soft&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>rf</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>nn</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(max_iter=20, random_state=42)</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>svm</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(probability=True, random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('rf', rf_clf), ('nn', nn_clf), ('svm', svm_clf)],\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "voting_clf.fit(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T13:01:53.873846100Z",
     "start_time": "2024-01-03T12:42:40.330166700Z"
    }
   },
   "id": "4c841df2911e37bd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate the voting classifier on the test set.\n",
    "# The voting classifier is able to use the strengths of all 3 models in order to have a higher prediction score than their standalone alternatives. Using the soft vot rule it takes only the prediction with the highest average of probabilities. Hence why we got better result. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b241c691bd380c09"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier accuracy: 0.9727142857142858\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the voting classifier on the validation set\n",
    "y_val_pred_voting = voting_clf.predict(X_val)\n",
    "print(f\"Voting Classifier accuracy: {accuracy_score(y_val, y_val_pred_voting)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T13:06:00.491136300Z",
     "start_time": "2024-01-03T13:05:10.812331600Z"
    }
   },
   "id": "1b781a8962590e44"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# After training individual classifiers, I applied stacking to harness their diverse insights effectively. I generated predictions from each classifier on the validation set, creating a new training set with these predictions as features. Using a Random Forest as a blender, I trained it on this augmented dataset, enabling it to learn to weigh and combine the strengths of individual classifiers. This stacking ensemble was then evaluated on the test set by using predictions from each classifier as input for the blender. This approach aims to capture intricate patterns and relationships while maintaining robustness. The blending step allows for a more nuanced and accurate model, considering the diverse perspectives provided by individual classifiers."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "be7aa1d87bbc2a12"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Ensemble accuracy: 0.9725714285714285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikol\\PycharmProjects\\Ensembles\\.virtualenv\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nikol\\PycharmProjects\\Ensembles\\.virtualenv\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nikol\\PycharmProjects\\Ensembles\\.virtualenv\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nikol\\PycharmProjects\\Ensembles\\.virtualenv\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nikol\\PycharmProjects\\Ensembles\\.virtualenv\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nikol\\PycharmProjects\\Ensembles\\.virtualenv\\venv\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier accuracy: 0.9801428571428571\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions on the validation set for blender training\n",
    "X_val_blend = np.column_stack([clf.predict(X_val) for clf in classifiers])\n",
    "\n",
    "# Train a blender on the new training set\n",
    "blender = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "blender.fit(X_val_blend, y_val)\n",
    "\n",
    "# Evaluate the stacking ensemble on the test set\n",
    "X_test_blend = np.column_stack([clf.predict(X_test) for clf in classifiers])\n",
    "y_test_pred_stack = blender.predict(X_test_blend)\n",
    "print(f\"Stacking Ensemble accuracy: {accuracy_score(y_test, y_test_pred_stack)}\")\n",
    "\n",
    "# Use StackingClassifier instead\n",
    "stacking_clf = StackingClassifier(estimators=[('rf', rf_clf), ('nn', nn_clf), ('svm', svm_clf)],\n",
    "                                  final_estimator=RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "stacking_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the stacking classifier on the test set\n",
    "y_test_pred_stacking = stacking_clf.predict(X_test)\n",
    "print(f\"Stacking Classifier accuracy: {accuracy_score(y_test, y_test_pred_stacking)}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-03T14:38:31.617789900Z",
     "start_time": "2024-01-03T13:06:00.502087100Z"
    }
   },
   "id": "94242e861ddfdebb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# The Stacking Ensemble accuracy is 97.26%, while the Stacking Classifier accuracy is slightly higher at 98.01%. The reason for the stacking classifier to outperform the stacking ensemble is the final layer. In the stacking ensemble, the blender takes the individual predictions from the classifiers and makes the final decision. While in the stacking classifier, the final layer is a classifier itself. This allows the stacking classifier to learn the best way to combine the predictions from the individual classifiers. This additional layer enables it to outperform the stacking ensemble by capturing more intricate relationships and patterns in the data, leading to better generalization and overall better accuracy."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aeb6754f774aaeef"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
